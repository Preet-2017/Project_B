{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4122329b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved as a.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(\"beyondb_authors_reply_with_emotions.csv\")\n",
    "\n",
    "# Remove the column\n",
    "if \"cleaned_authors_comment\" in df.columns:\n",
    "    df = df.drop(columns=[\"cleaned_authors_comment\"])\n",
    "\n",
    "# Remove rows where Author_replied == 0\n",
    "df = df[df[\"Author_replied\"] != 0]\n",
    "\n",
    "# Save new file\n",
    "df.to_csv(\"a.csv\", index=False)\n",
    "\n",
    "print(\"File saved as a.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68bd630a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved as a.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(\"unlabeled_with_author_emotion_predictions.csv\")\n",
    "\n",
    "# Remove the column\n",
    "if \"cleaned_post_content\" in df.columns:\n",
    "    df = df.drop(columns=[\"cleaned_post_content\"])\n",
    "if \"cleaned_authors_comment\" in df.columns:\n",
    "    df = df.drop(columns=[\"cleaned_authors_comment\"])\n",
    "if \"cleaned_comments_content\" in df.columns:\n",
    "    df = df.drop(columns=[\"cleaned_comments_content\"])\n",
    "\n",
    "if \"comments_sentiment\" in df.columns:\n",
    "    df = df.drop(columns=[\"comments_sentiment\"])\n",
    "if \"cleaned_authors_comment\" in df.columns:\n",
    "    df = df.drop(columns=[\"cleaned_authors_comment\"])\n",
    "if \"input_text\" in df.columns:\n",
    "    df = df.drop(columns=[\"input_text\"])    \n",
    "\n",
    "\n",
    "# Remove rows where Author_replied == 0\n",
    "df = df[df[\"Author_replied\"] == 0]\n",
    "\n",
    "# Save new file\n",
    "df.to_csv(\"b.csv\", index=False)\n",
    "\n",
    "print(\"File saved as a.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89235f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved as a.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"a.csv\")\n",
    "\n",
    "# Convert dict-like strings into actual dicts if needed\n",
    "df[\"pred_authors_reply_probabilities\"] = df[\"pred_authors_reply_probabilities\"].apply(\n",
    "    lambda x: ast.literal_eval(x) if isinstance(x, str) else x\n",
    ")\n",
    "\n",
    "# Extract probability that matches the emotion label\n",
    "df[\"matched_probability\"] = df.apply(\n",
    "    lambda row: row[\"pred_authors_reply_probabilities\"].get(row[\"pred_authors_reply_emotions\"], None),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "df = df.drop(columns=[\"pred_authors_reply_probabilities\"])\n",
    "\n",
    "# Save output\n",
    "df.to_csv(\"a.csv\", index=False)\n",
    "print(\"Saved as a.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e9a623c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged file saved as merged_author_A_B_final_emotions.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load both CSVs\n",
    "df1 = pd.read_csv(\"a.csv\")\n",
    "df2 = pd.read_csv(\"b.csv\")\n",
    "\n",
    "# Merge by stacking rows\n",
    "merged = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "# Save merged file\n",
    "merged.to_csv(\"merged_author_A_B_final_emotions.csv\", index=False)\n",
    "\n",
    "print(\"Merged file saved as merged_author_A_B_final_emotions.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a74796dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 12763\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"merged_author_A_B_final_emotions.csv\")\n",
    "print(\"Total rows:\", len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aae86d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved as all_threads_with_emotions.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load both CSVs\n",
    "posts = pd.read_csv(\"beyondb_post_predictions.csv\")  # forum_name,thread_id,cleaned_post_content,pred_emotions,pred_probabilities\n",
    "authors = pd.read_csv(\"merged_author_A_B_final_emotions.csv\")  # forum_name,thread_id,Author_replied,pred_authors_reply_emotions,pred_authors_reply_probabilities\n",
    "\n",
    "# Merge on forum_name and thread_id\n",
    "merged = pd.merge(\n",
    "    posts,\n",
    "    authors,\n",
    "    on=[\"forum_name\", \"thread_id\"],\n",
    "    how=\"inner\"   # use \"inner\" so only matching thread_id/forum_name pairs are kept\n",
    ")\n",
    "\n",
    "# Map Author_replied -> Cohort (1 -> A, 0 -> B)\n",
    "def to_cohort(x):\n",
    "    try:\n",
    "        v = int(x)\n",
    "    except Exception:\n",
    "        return None\n",
    "    if v == 1:\n",
    "        return \"A\"\n",
    "    elif v == 0:\n",
    "        return \"B\"\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "merged[\"Cohort\"] = merged[\"Author_replied\"].apply(to_cohort)\n",
    "\n",
    "# Rename columns as requested\n",
    "merged = merged.rename(columns={\n",
    "    \"cleaned_post_content\": \"post_content\",\n",
    "    \"pred_emotions\": \"initial_emotion\",\n",
    "    \"pred_probabilities\": \"initial_prob\",\n",
    "    \"pred_authors_reply_emotions\": \"final_pred_emotion\",\n",
    "    \"pred_authors_reply_probabilities\": \"final_pred_prob\"\n",
    "})\n",
    "\n",
    "# Select columns in the final desired order\n",
    "final_df = merged[\n",
    "    [\n",
    "        \"forum_name\",\n",
    "        \"thread_id\",\n",
    "        \"post_content\",\n",
    "        \"Cohort\",\n",
    "        \"initial_emotion\",\n",
    "        \"initial_prob\",\n",
    "        \"final_pred_emotion\",\n",
    "        \"final_pred_prob\"\n",
    "    ]\n",
    "]\n",
    "\n",
    "# Save to new CSV\n",
    "final_df.to_csv(\"all_threads_with_emotions.csv\", index=False)\n",
    "print(\"Saved as all_threads_with_emotions.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e0d3c616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved as final_dataset.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v8/hnghsvb16hqgpbjwl4mg79rw0000gn/T/ipykernel_7378/1902560717.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df[\"initial_prob\"] = final_df[\"initial_prob\"].apply(\n",
      "/var/folders/v8/hnghsvb16hqgpbjwl4mg79rw0000gn/T/ipykernel_7378/1902560717.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df[\"initial_prob\"] = final_df.apply(\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import numpy as np\n",
    "\n",
    "# Convert dict-like strings into dicts, leave floats/NaN unchanged\n",
    "final_df[\"initial_prob\"] = final_df[\"initial_prob\"].apply(\n",
    "    lambda x: ast.literal_eval(x) if isinstance(x, str) and x.startswith(\"{\") else x\n",
    ")\n",
    "\n",
    "# Extract matching probability ONLY when it's a dict\n",
    "final_df[\"initial_prob\"] = final_df.apply(\n",
    "    lambda row: row[\"initial_prob\"].get(row[\"initial_emotion\"], None)\n",
    "    if isinstance(row[\"initial_prob\"], dict)\n",
    "    else row[\"initial_prob\"],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Save updated dataframe to CSV\n",
    "final_df.to_csv(\"final_dataset.csv\", index=False)\n",
    "print(\"Saved as final_dataset.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
